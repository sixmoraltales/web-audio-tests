<html>
<head>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <style>
    body {
      margin: 0px;
      padding: 0px;
      --hue1: 176;
      --hue2: 341;
    }

    button {
        padding: 10px;
        background-color: black;
        color: aliceblue;
        font-family: Arial, Helvetica, sans-serif;
    }

    #container {
      width: 100vw;
      height: 100vh;
      background: radial-gradient(50% 50% at 50% 50%, hsl(var(--hue1), 90%, 80%, 1) 0%, hsl(var(--hue2), 90%, 80%, 1) 100%) 50% 50% / 100% 100% no-repeat;
    }
  </style>
</head>
<body>
    <div id="container">
        <!-- <button id="startAnimationBtn">Start</button>
        <button id="stopAnimationBtn">Stop</button> -->
        <button id="start-button">Start Camera</button>
        <div id="predictions"></div>
      </div>
  <video id="video" width="640" height="480" autoplay muted></video>
  <script>
    var startAnimationBtn = document.getElementById("startAnimationBtn");
    var stopAnimationBtn = document.getElementById("stopAnimationBtn");
    var newHue1;
    var newHue2;

    var currentHue1;
    var currentHue2;

    var hueDiff1;
    var hueDiff2;

    var incrementer1 = 0;
    var incrementer2 = 0;

    var counter = 0;
    var iterations = 100;

    function setNewColor() {

      var bodyStyle = getComputedStyle(document.body);

      currentHue1 = Number(bodyStyle.getPropertyValue("--hue1"));
      currentHue2 = Number(bodyStyle.getPropertyValue("--hue2"));

      newHue1 = getRandomNumber(0, 360);
      newHue2 = getRandomNumber(0, 360);

      hueDiff1 = newHue1 - currentHue1;
      hueDiff2 = newHue2 - currentHue2;

      incrementer1 = hueDiff1 / iterations;
      incrementer2 = hueDiff2 / iterations;
    }

    function animate() {

      if (counter == 0) {
        setNewColor();
      }
      
      counter++;

      currentHue1 += incrementer1;
      currentHue2 += incrementer2;

      if (counter == iterations) {
        cancelAnimation;
        counter = 0;
      } else {
        document.body.style.setProperty("--hue1", currentHue1);
      document.body.style.setProperty("--hue2", currentHue2);

      latestFrame = requestAnimationFrame(animate);
      }

      
    }

    function cancelAnimation() {
        cancelAnimationFrame(latestFrame);
    }

    function getRandomNumber(low, high) {
      var r = Math.floor(Math.random() * (high - low + 1)) + low;
      return r;
    }

    var dorianChord = [261.63, 329.63, 392, 523.25]; // C Dorian: C min6, F 9
    var phrygianChord = [261.63, 277.18, 349.23, 415.3]; // C Phrygian: C min, D♭ maj
    var lydianChord = [261.63, 329.63, 415.3, 493.88]; // C Lydian: C maj7♭5, B -7
    var mixolydianChord = [261.63, 329.63, 392, 466.16]; // C Mixolydian: C 13, E -7♭5

    // Create an array of modal chords
    var modalChords = [dorianChord, phrygianChord, lydianChord, mixolydianChord];

    // Get the video element and the start button
    const video = document.getElementById("video");
    const startButton = document.getElementById("start-button");

    // Define variables for audio context
    let audioContext;
    var convolver

    // Flags to track detection state of each object type
    let personDetected = false;
    let cellphoneDetected = false;
    let chairDetected = false;

    // Load the COCO-SSD model
    let model;
    cocoSsd.load().then(loadedModel => {
      model = loadedModel;
      console.log("Model loaded");
    });

    // Define a function to start the camera and audio context
    function startCamera() {
      // Initialize the audio context
      audioContext = new AudioContext();

      // Create a gain node for the volume
      var gainNode = audioContext.createGain();
      gainNode.gain.value = 0.1; // Set the volume to 50%

      // Connect the gain node to the destination (speakers)
      gainNode.connect(audioContext.destination);

      // Create a convolver node for the reverb effect
      convolver = audioContext.createConvolver();

      // Fetch the impulse response from the local directory
      fetch("6 Spaces 06 Scoring Stage  M-to-S.wav")
        .then(response => response.arrayBuffer())
        .then(arrayBuffer => audioContext.decodeAudioData(arrayBuffer))
        .then(audioBuffer => {
          // Set the impulse response to the convolver
          convolver.buffer = audioBuffer;

          // Connect the convolver to the gain node
          convolver.connect(gainNode);
        })
        .catch(e => console.error(e));

      // Ask for permission to access the camera
      navigator.mediaDevices.getUserMedia({video: true})
        .then(stream => {
          // Set the video source to the stream
          video.srcObject = stream;
          // Start the video
          video.play();
          // Run the object detection every 100 milliseconds
          setInterval(runDetection, 100);
        })
        .catch(error => {
          // Handle the error
          console.error(error);
          alert("Please allow access to the camera");
        });
    }

    function playRandomModalChord() {
      // Generate a random number between 0 and 3
      var randomIndex = Math.floor(Math.random() * 4);

      // Select a random modal chord from the array
      var modalChord = modalChords[randomIndex];

      // Loop through the frequencies of the modal chord
      for (var i = 0; i < modalChord.length; i++) {
        // Create a sine wave oscillator for each frequency
        var oscillator = audioContext.createOscillator();
        oscillator.type = "sine";
        oscillator.frequency.value = modalChord[i];

        // Create a gain node for the envelope
        var envelope = audioContext.createGain();
        envelope.gain.value = 0; // Initial volume

        // Connect the oscillator to the envelope
        oscillator.connect(envelope);

        // Connect the envelope to the convolver
        envelope.connect(convolver);

        // Start the oscillator
        oscillator.start();

        // Create a new time constant for the envelope
        var now = audioContext.currentTime;

        // Set the envelope parameters
        var attack = 0.1; // Time to reach maximum volume
        var decay = 0.2; // Time to reach sustain volume
        var sustain = 0.5; // Sustain volume level
        var release = 0.5; // Time to reach zero volume

        // Apply the envelope to the gain node
        envelope.gain.cancelScheduledValues(now); // Cancel any previous changes
        envelope.gain.setValueAtTime(0, now); // Set the initial volume to zero
        envelope.gain.linearRampToValueAtTime(1, now + attack); // Ramp up to maximum volume
        envelope.gain.linearRampToValueAtTime(sustain, now + attack + decay); // Ramp down to sustain volume
        envelope.gain.linearRampToValueAtTime(0, now + attack + decay + release); // Ramp down to zero volume

        // Stop the oscillator after the release time
        oscillator.stop(now + attack + decay + release);
      }

      // Set the flag to true
      isPlaying = true;

      // Set a timeout to reset the flag after the release time
      setTimeout(function() {
        isPlaying = false;
      }, (attack + decay + release) * 1000);
    }

    // Define a function to run the object detection
    function runDetection() {
      // Check if the model is loaded
      if (model) {
        // Detect objects in the video frame
        model.detect(video)
          .then(predictions => {
            // Reset detection flags if no objects are detected
            if (predictions.length === 0) {
              personDetected = cellphoneDetected = chairDetected = false;
            }

            predictions.forEach(prediction => {
              // Check for new detections and play sound accordingly
              if (prediction.class === 'person' && !personDetected) {
                animate();
                playRandomModalChord();
                personDetected = true;
              } else if (prediction.class === 'cell phone' && !cellphoneDetected) {
                animate();
                playRandomModalChord();
                cellphoneDetected = true;
              } else if (prediction.class === 'chair' && !chairDetected) {
                animate();
                playRandomModalChord();
                chairDetected = true;
              }
            });

            // Display the predictions on the webpage
            displayPredictions(predictions);
          });
      }
    }

    // Define a function to display predictions
    function displayPredictions(predictions) {
      // Clear any previous predictions displayed
      const predictionsContainer = document.getElementById("predictions");
      predictionsContainer.innerHTML = '';

      // Create elements for each prediction and add to the container
      predictions.forEach(prediction => {
        const p = document.createElement("p");
        p.innerText = `Detected: ${prediction.class} with ${Math.round(prediction.score * 100)}% confidence`;
        predictionsContainer.appendChild(p);
      });
    }

    // Add a click event listener to the start button
    startButton.addEventListener("click", startCamera);
  </script>
</body>
</html>